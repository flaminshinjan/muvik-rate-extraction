{"version":3,"file":"agent/helper.js","sources":["webpack://@agent-infra/browser-use/./src/agent/helper.ts"],"sourcesContent":["/**\n * The following code is modified based on\n * https://github.com/nanobrowser/nanobrowser/blob/master/chrome-extension/src/background/agent/helper.ts\n *\n * Apache-2.0 License\n * Copyright (c) 2024 alexchenzl\n * https://github.com/nanobrowser/nanobrowser/blob/master/LICENSE\n */\nimport {\n  type ProviderConfig,\n  LLMProviderEnum,\n  AgentNameEnum,\n} from '../context';\nimport { AzureChatOpenAI } from '@langchain/openai';\nimport type { BaseChatModel } from '@langchain/core/language_models/chat_models';\nimport { createLogger } from '../utils';\n\nconst logger = createLogger('agent_helper');\n\n// create a chat model based on the agent name, the model name and provider\nexport function createChatModel(\n  agentName: string,\n  providerName: LLMProviderEnum,\n  providerConfig: ProviderConfig,\n  modelName: string,\n): BaseChatModel {\n  const maxTokens = 2000;\n  const maxCompletionTokens = 5000;\n  let temperature = 0;\n  const topP = 0.001;\n  switch (providerName) {\n    case LLMProviderEnum.AzureOpenAI: {\n      if (agentName === AgentNameEnum.Planner) {\n        temperature = 0.02;\n      }\n      const args: any = {\n        model: modelName,\n        apiKey: providerConfig.apiKey,\n        configuration: {},\n      };\n      if (providerConfig.baseUrl) {\n        args.configuration = {\n          baseURL: providerConfig.baseUrl,\n        };\n      }\n\n      // O series models have different parameters\n      if (modelName.startsWith('o')) {\n        args.modelKwargs = {\n          max_completion_tokens: maxCompletionTokens,\n        };\n      } else {\n        args.topP = topP;\n        args.temperature = temperature;\n        args.maxTokens = maxTokens;\n      }\n      logger.info('azure args', args);\n      return new AzureChatOpenAI(args);\n    }\n    default: {\n      throw new Error(`Provider ${providerName} not supported yet`);\n    }\n  }\n}\n"],"names":["logger","createLogger","createChatModel","agentName","providerName","providerConfig","modelName","maxTokens","maxCompletionTokens","temperature","topP","LLMProviderEnum","AgentNameEnum","args","AzureChatOpenAI","Error"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,MAAMA,SAASC,AAAAA,IAAAA,kCAAAA,YAAAA,AAAAA,EAAa;AAGrB,SAASC,gBACdC,SAAiB,EACjBC,YAA6B,EAC7BC,cAA8B,EAC9BC,SAAiB;IAEjB,MAAMC,YAAY;IAClB,MAAMC,sBAAsB;IAC5B,IAAIC,cAAc;IAClB,MAAMC,OAAO;IACb,OAAQN;QACN,KAAKO,oCAAAA,eAAAA,CAAAA,WAA2B;YAAE;gBAChC,IAAIR,cAAcS,oCAAAA,aAAAA,CAAAA,OAAqB,EACrCH,cAAc;gBAEhB,MAAMI,OAAY;oBAChB,OAAOP;oBACP,QAAQD,eAAe,MAAM;oBAC7B,eAAe,CAAC;gBAClB;gBACA,IAAIA,eAAe,OAAO,EACxBQ,KAAK,aAAa,GAAG;oBACnB,SAASR,eAAe,OAAO;gBACjC;gBAIF,IAAIC,UAAU,UAAU,CAAC,MACvBO,KAAK,WAAW,GAAG;oBACjB,uBAAuBL;gBACzB;qBACK;oBACLK,KAAK,IAAI,GAAGH;oBACZG,KAAK,WAAW,GAAGJ;oBACnBI,KAAK,SAAS,GAAGN;gBACnB;gBACAP,OAAO,IAAI,CAAC,cAAca;gBAC1B,OAAO,IAAIC,uBAAAA,eAAeA,CAACD;YAC7B;QACA;YACE,MAAM,IAAIE,MAAM,CAAC,SAAS,EAAEX,aAAa,kBAAkB,CAAC;IAEhE;AACF"}